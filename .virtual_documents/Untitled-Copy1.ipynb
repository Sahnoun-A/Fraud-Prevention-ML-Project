














import pandas as pd

# Load the CSV file
data = pd.read_csv('ecom_txns.csv')

# Display the first few rows of the dataset
data.head()





import geoip2.database


# Initialize the reader
reader = geoip2.database.Reader('GeoLite2-Country.mmdb')

# Function to fetch country from IP address
def get_country_from_ip(ip):
    try:
        response = reader.country(ip)
        return response.country.name
    except:
        return "Unknown"

# Apply the function to the dataset
data['Country'] = data['ip_address'].apply(get_country_from_ip)

# Close the reader
reader.close()



# Display the updated dataset
data.head()


from IPython.display import FileLink

# Save the DataFrame as a CSV file
data.to_csv('updated_file.csv', index=False)

# Create a link to download the file
FileLink(r'updated_file.csv')





import matplotlib.pyplot as plt

# Visualize the fraud distribution
fraud_counts = data['fraud'].value_counts()
plt.figure(figsize=(6, 4))
fraud_counts.plot(kind='bar', color=['blue', 'orange'])
plt.title('Fraud Distribution')
plt.xticks(ticks=[0, 1], labels=['Legitimate', 'Fraud'])
plt.ylabel('Count')
plt.xlabel('Transaction Type')
plt.show()

# Visualize transaction amounts for fraudulent vs. legitimate transactions
plt.figure(figsize=(10, 6))
data.boxplot(column='amount', by='fraud', showfliers=False)
plt.title('Transaction Amounts by Fraud Status')
plt.suptitle('')  # Remove default title
plt.xlabel('Fraud Status (0=Legitimate, 1=Fraud)')
plt.ylabel('Transaction Amount')
plt.show()

# Visualize age distribution for fraudulent vs. legitimate transactions
plt.figure(figsize=(10, 6))
data[data['fraud'] == 0]['age'].plot(kind='density', label='Legitimate', alpha=0.7)
data[data['fraud'] == 1]['age'].plot(kind='density', label='Fraud', alpha=0.7)
plt.title('Age Distribution by Fraud Status')
plt.xlabel('Age')
plt.legend()
plt.show()

# Visualize fraud cases by country
top_countries = data['Country'].value_counts().head(10).index
fraud_by_country = data[data['Country'].isin(top_countries)].groupby('Country')['fraud'].sum()
plt.figure(figsize=(10, 6))
fraud_by_country.plot(kind='bar', color='green')
plt.title('Fraud Cases by Country (Top 10 Countries)')
plt.xlabel('Country')
plt.ylabel('Number of Fraudulent Transactions')
plt.show()












# Analyze missing values
missing_values = data.isnull().sum()
missing_percentage = (missing_values / len(data)) * 100

# Create a DataFrame to summarize missing value information
missing_summary = pd.DataFrame({
    'Missing Values': missing_values,
    'Percentage (%)': missing_percentage
}).sort_values(by='Missing Values', ascending=False)

# Display the summary in tabular format
from IPython.display import display
display(missing_summary)






# Replace missing values in 'Country' with 'Unknown'
#data['Country'].fillna('Unknown', inplace=True)
data.fillna({'Country':'Unknown'}, inplace=True)

# Verify if missing values in 'Country' have been handled
missing_values_after = data['Country'].isnull().sum()
missing_values_after






# Copy data to handle transformations
data_encoded = data.copy()

# Encode categorical variables using label encoding or similar methods
categorical_cols = ['store', 'browser', 'sex', 'Country']
for col in categorical_cols:
    data_encoded[col] = data_encoded[col].astype('category').cat.codes

# Drop non-numeric columns that can't be directly converted to numeric
non_numeric_cols = ['signup_datetime', 'datetime', 'ip_address']
data_encoded = data_encoded.drop(columns=non_numeric_cols, errors='ignore')

# Calculate the correlation matrix
correlation_matrix = data_encoded.corr()

# Focus on correlations with the 'fraud' target variable
fraud_correlation = correlation_matrix['fraud'].sort_values(ascending=False)

# Display the results
print(fraud_correlation)









# 1. Transaction Amount vs. Fraud (Boxplot)
plt.figure(figsize=(10, 6))
data.boxplot(column='amount', by='fraud', showfliers=False)
plt.title('Transaction Amounts by Fraud Status')
plt.suptitle('')  # Remove default title
plt.xlabel('Fraud Status (0=Legitimate, 1=Fraud)')
plt.ylabel('Transaction Amount')
plt.show()

# 2. Fraud Rate by Browser
browser_fraud_rate = data.groupby('browser')['fraud'].mean().sort_values(ascending=False)
plt.figure(figsize=(10, 6))
browser_fraud_rate.plot(kind='bar', color='purple')
plt.title('Fraud Rate by Browser')
plt.xlabel('Browser')
plt.ylabel('Fraud Rate')
plt.show()

# 3. Fraud Rate by Store
store_fraud_rate = data.groupby('store')['fraud'].mean().sort_values(ascending=False)
plt.figure(figsize=(10, 6))
store_fraud_rate.plot(kind='bar', color='orange')
plt.title('Fraud Rate by Store')
plt.xlabel('Store')
plt.ylabel('Fraud Rate')
plt.show()

# 4. Fraud by Signup Time (Hour of Day)
data['signup_hour'] = pd.to_datetime(data['signup_datetime']).dt.hour
signup_hour_fraud = data.groupby('signup_hour')['fraud'].mean()
plt.figure(figsize=(10, 6))
signup_hour_fraud.plot(kind='line', marker='o')
plt.title('Fraud Rate by Signup Hour')
plt.xlabel('Signup Hour')
plt.ylabel('Fraud Rate')
plt.grid()
plt.show()

# 5. Fraud by Country
top_countries = data['Country'].value_counts().head(10).index
fraud_by_country = data[data['Country'].isin(top_countries)].groupby('Country')['fraud'].sum()
plt.figure(figsize=(10, 6))
fraud_by_country.plot(kind='bar', color='green')
plt.title('Fraud Cases by Country (Top 10 Countries)')
plt.xlabel('Country')
plt.ylabel('Number of Fraudulent Transactions')
plt.show()

# 6. Fraud by Age Group
data['age_group'] = pd.cut(data['age'], bins=[0, 18, 25, 35, 50, 100], labels=['<18', '18-25', '26-35', '36-50', '>50'])
age_group_fraud_rate = data.groupby('age_group')['fraud'].mean()
plt.figure(figsize=(10, 6))
age_group_fraud_rate.plot(kind='bar', color='blue')
plt.title('Fraud Rate by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Fraud Rate')
plt.show()










import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# 1. Date-Time Features
data['signup_datetime'] = pd.to_datetime(data['signup_datetime'])
data['datetime'] = pd.to_datetime(data['datetime'])

# Extracting transaction hour, day of week, and time difference
data['transaction_hour'] = data['datetime'].dt.hour
data['transaction_day'] = data['datetime'].dt.dayofweek
data['time_since_signup'] = (data['datetime'] - data['signup_datetime']).dt.total_seconds() / 3600  # Hours

# 2. Categorical Encoding
# One-hot encode 'store' and 'browser'
encoder = OneHotEncoder(drop='first', sparse_output=False)
categorical_encoded = pd.DataFrame(
    encoder.fit_transform(data[['store', 'browser']]),
    columns=encoder.get_feature_names_out(['store', 'browser'])
)

data = pd.concat([data, categorical_encoded], axis=1)

# Frequency encoding for 'Country'
country_frequency = data['Country'].value_counts(normalize=True)
data['country_frequency'] = data['Country'].map(country_frequency)

# Encode 'sex' as numeric
data['sex'] = data['sex'].astype('category').cat.codes

# 3. Numerical Feature Transformation
scaler = StandardScaler()
data[['amount', 'age', 'time_since_signup']] = scaler.fit_transform(data[['amount', 'age', 'time_since_signup']])

# 4. Interaction Features
data['device_browser'] = data['device_id'].astype(str) + "_" + data['browser']
data['country_store'] = data['Country'].astype(str) + "_" + data['store']

# Encoding interaction features (frequency encoding for simplicity)
device_browser_freq = data['device_browser'].value_counts(normalize=True)
country_store_freq = data['country_store'].value_counts(normalize=True)
data['device_browser_freq'] = data['device_browser'].map(device_browser_freq)
data['country_store_freq'] = data['country_store'].map(country_store_freq)

# 5. Aggregated User Behavior
user_aggregates = data.groupby('user_id').agg({
    'amount': ['mean', 'std'],
    'fraud': 'sum'
}).reset_index()

user_aggregates.columns = ['user_id', 'user_avg_amount', 'user_std_amount', 'user_fraud_history']

data = data.merge(user_aggregates, on='user_id', how='left')

# Dropping unnecessary columns for modeling
columns_to_drop = [
    'signup_datetime', 'datetime', 'ip_address', 'store', 'browser', 'Country',
    'device_id', 'device_browser', 'country_store'
]
data_model = data.drop(columns=columns_to_drop, errors='ignore')

# Display the summary in tabular format
from IPython.display import display
display(data_model)


#6. numerical feature normalization
# Select numerical columns to normalize
numerical_columns = ['amount', 'age']

# Normalize numerical columns using StandardScaler
scaler = StandardScaler()
data[numerical_columns] = scaler.fit_transform(data[numerical_columns])

# Verify normalization by inspecting the first few rows
data[numerical_columns].head()








data


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, roc_auc_score

# Prepare the dataset

# Check and encode the 'age_group' column
if 'age_group' in data_model.columns:
    data_model['age_group'] = data_model['age_group'].astype('category').cat.codes

# Handle Missing Values
if data_model.isnull().sum().any():
    # Fill missing numerical values with the median
    for col in data_model.select_dtypes(include=np.number).columns:
        data_model[col].fillna(data_model[col].median(), inplace=True)
    
    # Fill missing categorical values with the mode
    for col in data_model.select_dtypes(include='object').columns:
        data_model[col].fillna(data_model[col].mode()[0], inplace=True)

# Target variable: 'fraud'
# Features: Drop non-feature columns and the target variable
target = 'fraud'
X = data_model.drop(columns='fraud')
y = data_model[target]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Step 2: Baseline Models
# Logistic Regression
log_reg = LogisticRegression(class_weight='balanced', random_state=42)
log_reg.fit(X_train, y_train)
log_reg_preds = log_reg.predict(X_test)
log_reg_probs = log_reg.predict_proba(X_test)[:, 1]

# Decision Tree
tree_clf = DecisionTreeClassifier(class_weight='balanced', random_state=42)
tree_clf.fit(X_train, y_train)
tree_preds = tree_clf.predict(X_test)
tree_probs = tree_clf.predict_proba(X_test)[:, 1]

# Evaluation for Baseline Models
log_reg_report = classification_report(y_test, log_reg_preds, output_dict=True)
tree_clf_report = classification_report(y_test, tree_preds, output_dict=True)

log_reg_auc = roc_auc_score(y_test, log_reg_probs)
tree_clf_auc = roc_auc_score(y_test, tree_probs)

baseline_results = {
    "Logistic Regression": {"Report": log_reg_report, "AUC": log_reg_auc},
    "Decision Tree": {"Report": tree_clf_report, "AUC": tree_clf_auc},
}

baseline_results



from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, roc_auc_score
import pandas as pd



# Initialize models
models = {
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
    "Random Forest": RandomForestClassifier(random_state=42, n_estimators=100),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "Naive Bayes": GaussianNB()
}

# Dictionary to store evaluation results
evaluation_results = {}

# Train and evaluate each model
for model_name, model in models.items():
    # Train the model
    model.fit(X_train, y_train)
    
    # Make predictions
    preds = model.predict(X_test)
    probs = model.predict_proba(X_test)[:, 1]

    # Evaluate the model
    report = classification_report(y_test, preds, output_dict=True)
    roc_auc = roc_auc_score(y_test, probs)

    # Store the results
    evaluation_results[model_name] = {
        "Precision": report['1']['precision'],
        "Recall": report['1']['recall'],
        "F1-Score": report['1']['f1-score'],
        "ROC-AUC": roc_auc
    }

# Convert results to a DataFrame for better visualization
results_df = pd.DataFrame(evaluation_results).T

# Display the results
display(results_df)



import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score



# Define hyperparameter grids for both models
rf_param_grid = {
    "n_estimators": [50, 100, 200],
    "max_depth": [10, 20, None],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
}

xgb_param_grid = {
    "n_estimators": [50, 100, 200],
    "max_depth": [3, 6, 10],
    "learning_rate": [0.01, 0.1, 0.2],
    "subsample": [0.6, 0.8, 1.0],
}

# Random Forest Grid Search
rf_grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=rf_param_grid,
    scoring="roc_auc",
    cv=3,
    n_jobs=-1,
    verbose=1,
)
rf_grid_search.fit(X_train, y_train)

# XGBoost Grid Search
xgb_grid_search = GridSearchCV(
    estimator=XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42),
    param_grid=xgb_param_grid,
    scoring="roc_auc",
    cv=3,
    n_jobs=-1,
    verbose=1,
)
xgb_grid_search.fit(X_train, y_train)

# Best parameters and scores
rf_best_params = rf_grid_search.best_params_
rf_best_score = rf_grid_search.best_score_

xgb_best_params = xgb_grid_search.best_params_
xgb_best_score = xgb_grid_search.best_score_

# Display the results
print("Random Forest Best Parameters:", rf_best_params)
print("Random Forest Best ROC-AUC (CV):", rf_best_score)

print("XGBoost Best Parameters:", xgb_best_params)
print("XGBoost Best ROC-AUC (CV):", xgb_best_score)



import matplotlib.pyplot as plt
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Assuming the models have been fine-tuned and refit with the best parameters
# Random Forest Feature Importance
rf_model = RandomForestClassifier(**rf_best_params, random_state=42)
rf_model.fit(X_train, y_train)

# XGBoost Feature Importance
xgb_model = XGBClassifier(**xgb_best_params, use_label_encoder=False, eval_metric="logloss", random_state=42)
xgb_model.fit(X_train, y_train)

# Random Forest Feature Importance Plot
rf_importances = rf_model.feature_importances_
rf_features = X.columns

plt.figure(figsize=(10, 6))
plt.barh(rf_features, rf_importances)
plt.title("Random Forest Feature Importances")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()

# XGBoost Feature Importance Plot
xgb_importances = xgb_model.feature_importances_
xgb_features = X.columns

plt.figure(figsize=(10, 6))
plt.barh(xgb_features, xgb_importances)
plt.title("XGBoost Feature Importances")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()






pip install tensorflow


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Build the Neural Network
model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), 
              loss='binary_crossentropy', 
              metrics=['Precision', 'Recall', 'AUC'])

# Early stopping to avoid overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, 
                    validation_split=0.2, 
                    epochs=50, 
                    batch_size=32, 
                    callbacks=[early_stopping],
                    verbose=1)

# Evaluate on test data
results = model.evaluate(X_test, y_test, verbose=1)
print("Test Loss:", results[0])
print("Test Precision:", results[1])
print("Test Recall:", results[2])
print("Test AUC:", results[3])





pip install keras-tuner


import keras_tuner as kt
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Sequential

# Define the model building function for Keras Tuner
def build_model(hp):
    model = Sequential()
    # Input layer
    model.add(Dense(units=hp.Int('units_input', min_value=32, max_value=128, step=32), 
                    activation='relu', input_dim=X_train.shape[1]))
    # Hidden layers
    for i in range(hp.Int('num_layers', 1, 3)):
        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=128, step=32), activation='relu'))
        model.add(Dropout(hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))
    # Output layer
    model.add(Dense(1, activation='sigmoid'))
    
    # Compile the model
    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),
                  loss='binary_crossentropy',
                  metrics=['Precision', 'Recall', 'AUC'])
    return model



from keras_tuner.tuners import RandomSearch

# Define the tuner
tuner = RandomSearch(
    build_model,
    objective='val_loss',
    max_trials=10,  # Number of hyperparameter combinations to try
    executions_per_trial=2,  # Average performance over multiple runs
    directory='hyperparam_tuning',
    project_name='fraud_detection_nn'
)

# Run the search
tuner.search(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32, callbacks=[early_stopping], verbose=1)

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(f"Best hyperparameters: {best_hps.values}")

# Build the best model
best_model = tuner.hypermodel.build(best_hps)

# Train the best model on the full training set
history = best_model.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=32, callbacks=[early_stopping])



results = best_model.evaluate(X_test, y_test)
print("Test Loss:", results[0])
print("Test Precision:", results[1])
print("Test Recall:", results[2])
print("Test AUC:", results[3])



tuner.results_summary()


import matplotlib.pyplot as plt

# Function to plot training and validation metrics
def plot_training_history(history):
    # Extract metrics from the history object
    metrics = ['loss', 'precision', 'recall', 'auc']
    
    for metric in metrics:
        plt.figure(figsize=(8, 6))
        plt.plot(history.history[metric], label=f'Training {metric.capitalize()}')
        plt.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}')
        plt.title(f'Model {metric.capitalize()}')
        plt.xlabel('Epochs')
        plt.ylabel(metric.capitalize())
        plt.legend()
        plt.grid()
        plt.show()

# Call the function with the history object
plot_training_history(history)



from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict on the test set
y_pred = (best_model.predict(X_test) > 0.5).astype("int32")

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Fraud', 'Fraud'])
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()



from sklearn.metrics import roc_curve, auc

# Predict probabilities for the test set
y_probs = best_model.predict(X_test).ravel()

# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid()
plt.show()



from sklearn.metrics import precision_recall_curve, average_precision_score

# Compute the Precision-Recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_probs)
average_precision = average_precision_score(y_test, y_probs)

# Plot the Precision-Recall curve
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', label=f'Precision-Recall Curve (AP = {average_precision:.2f})')
plt.title('Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend(loc='upper right')
plt.grid()
plt.show()



# Plot the training and validation loss
plt.figure(figsize=(8, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Learning Curve')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()






import joblib

# Save the Random Forest model
joblib.dump(rf_model, 'random_forest_model.pkl')

# Save the XGBoost model
joblib.dump(xgb_model, 'xgboost_model.pkl')



from flask import Flask, request, jsonify

# Load the saved model
model = joblib.load('random_forest_model.pkl')

# Initialize the Flask app
app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    # Parse JSON input
    input_data = request.json
    df = pd.DataFrame(input_data)
    
    # Make predictions
    predictions = model.predict(df).tolist()
    probabilities = model.predict_proba(df)[:, 1].tolist()
    
    # Return the predictions
    return jsonify({'predictions': predictions, 'probabilities': probabilities})

if __name__ == '__main__':
    app.run(debug=True)




